{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d9413e",
   "metadata": {},
   "source": [
    "# LAB ASSIGNMENT 3 - Sentiment Analysis of Amazon Review\n",
    "\n",
    "Group Members:-\n",
    "\n",
    "Muhammad Fahmi Bin Misri (SW01081019)\n",
    "Nik Muhammad Nafis Bin Nik Azlan (SW01081028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95c1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import the necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1fc112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  I was wondering if anyone out there could enli...       7   \n",
       "1          17  I recently posted an article asking what kind ...       7   \n",
       "2          29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3          56  an excellent automatic can be found in the sub...       7   \n",
       "4          64  : Ford and his automobile.  I need information...       7   \n",
       "\n",
       "       title                        date  \n",
       "0  rec.autos  2022-08-02 13:48:37.251043  \n",
       "1  rec.autos  2022-08-02 13:48:37.251043  \n",
       "2  rec.autos  2022-08-02 13:48:37.251043  \n",
       "3  rec.autos  2022-08-02 13:48:37.251043  \n",
       "4  rec.autos  2022-08-02 13:48:37.251043  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6df7584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f263215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I was wondering if anyone out there could enli...\n",
       "1    I recently posted an article asking what kind ...\n",
       "2    \\nIt depends on your priorities.  A lot of peo...\n",
       "3    an excellent automatic can be found in the sub...\n",
       "4    : Ford and his automobile.  I need information...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select Text column\n",
    "df_t = df['text']\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad89f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "# check no. of duplicates in Text column\n",
    "df_t_duplicates = df_t.duplicated()\n",
    "print(df_t_duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7840cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10994,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates in Text column\n",
    "df_rdup = df_t.drop_duplicates(keep='first')\n",
    "df_rdup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cee1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read the data (use only the ‘text’ column)\n",
    "df = pd.read_csv('news_dataset.csv')\n",
    "df_text = df[['text']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfb13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform text pre-processing\n",
    "# Define the stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a7a99",
   "metadata": {},
   "source": [
    "Removing HTML tags and unwanted characters and Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f994095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords, lemmatizer, and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Stemming and Lemmatization\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Apply preprocessing and create new column\n",
    "df_text['processed'] = df_text['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5f55bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>[wonder, anyon, could, enlighten, car, saw, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>[recent, post, articl, ask, kind, rate, singl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>[depend, prioriti, lot, peopl, put, higher, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>[excel, automat, found, subaru, legaci, switch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>[ford, automobil, need, inform, whether, ford,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I was wondering if anyone out there could enli...   \n",
       "1  I recently posted an article asking what kind ...   \n",
       "2  \\nIt depends on your priorities.  A lot of peo...   \n",
       "3  an excellent automatic can be found in the sub...   \n",
       "4  : Ford and his automobile.  I need information...   \n",
       "\n",
       "                                           processed  \n",
       "0  [wonder, anyon, could, enlighten, car, saw, da...  \n",
       "1  [recent, post, articl, ask, kind, rate, singl,...  \n",
       "2  [depend, prioriti, lot, peopl, put, higher, pr...  \n",
       "3  [excel, automat, found, subaru, legaci, switch...  \n",
       "4  [ford, automobil, need, inform, whether, ford,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe with the new 'processed' column\n",
    "df_text[['text', 'processed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "941f9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(df_text['processed'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df_text['processed']]\n",
    "\n",
    "# Step 5: Perform LDA using Gensim\n",
    "lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf2cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the LDA model using Coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df_text['processed'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b9a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score (C_V): 0.6951\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Interpret the result\n",
    "print(f'Coherence Score (C_V): {coherence_lda:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14465ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.041*\"space\" + 0.016*\"nasa\" + 0.015*\"launch\" + 0.013*\"orbit\" + 0.010*\"satellit\" + 0.009*\"leaf\" + 0.009*\"earth\" + 0.008*\"mission\" + 0.007*\"moon\" + 0.007*\"rocket\"')\n",
      "(1, '0.012*\"would\" + 0.011*\"one\" + 0.010*\"peopl\" + 0.008*\"think\" + 0.008*\"like\" + 0.007*\"say\" + 0.007*\"know\" + 0.007*\"go\" + 0.007*\"get\" + 0.006*\"time\"')\n",
      "(2, '0.032*\"game\" + 0.025*\"team\" + 0.019*\"play\" + 0.016*\"player\" + 0.013*\"win\" + 0.012*\"season\" + 0.011*\"leagu\" + 0.009*\"hockey\" + 0.009*\"score\" + 0.008*\"turkey\"')\n",
      "(3, '0.010*\"govern\" + 0.007*\"state\" + 0.006*\"presid\" + 0.006*\"secur\" + 0.005*\"new\" + 0.005*\"mr\" + 0.005*\"law\" + 0.005*\"u\" + 0.005*\"public\" + 0.005*\"nation\"')\n",
      "(4, '0.022*\"use\" + 0.020*\"key\" + 0.012*\"encrypt\" + 0.010*\"chip\" + 0.009*\"system\" + 0.009*\"one\" + 0.008*\"bit\" + 0.007*\"would\" + 0.007*\"get\" + 0.006*\"window\"')\n",
      "(5, '0.049*\"god\" + 0.027*\"christian\" + 0.020*\"jesu\" + 0.017*\"jew\" + 0.014*\"church\" + 0.012*\"bibl\" + 0.012*\"believ\" + 0.011*\"faith\" + 0.011*\"religion\" + 0.010*\"christ\"')\n",
      "(6, '0.049*\"x\" + 0.016*\"edu\" + 0.016*\"file\" + 0.010*\"anonym\" + 0.009*\"com\" + 0.009*\"c\" + 0.009*\"use\" + 0.009*\"mail\" + 0.008*\"program\" + 0.007*\"ftp\"')\n",
      "(7, '0.017*\"car\" + 0.010*\"wire\" + 0.009*\"ground\" + 0.006*\"new\" + 0.006*\"ride\" + 0.005*\"hide\" + 0.005*\"water\" + 0.005*\"shot\" + 0.004*\"engin\" + 0.004*\"min\"')\n",
      "(8, '0.052*\"w\" + 0.050*\"b\" + 0.047*\"q\" + 0.038*\"p\" + 0.037*\"u\" + 0.034*\"r\" + 0.033*\"c\" + 0.033*\"g\" + 0.029*\"v\" + 0.028*\"n\"')\n",
      "(9, '0.621*\"ax\" + 0.047*\"max\" + 0.036*\"f\" + 0.028*\"q\" + 0.021*\"g\" + 0.018*\"v\" + 0.010*\"p\" + 0.008*\"r\" + 0.008*\"u\" + 0.006*\"b\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c8a5165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "space (0.0409)\n",
      "nasa (0.0155)\n",
      "launch (0.0146)\n",
      "orbit (0.0128)\n",
      "satellit (0.0098)\n",
      "leaf (0.0094)\n",
      "earth (0.0094)\n",
      "mission (0.0085)\n",
      "moon (0.0071)\n",
      "rocket (0.0067)\n",
      "\n",
      "Topic #2:\n",
      "would (0.0120)\n",
      "one (0.0114)\n",
      "peopl (0.0102)\n",
      "think (0.0080)\n",
      "like (0.0076)\n",
      "say (0.0074)\n",
      "know (0.0072)\n",
      "go (0.0070)\n",
      "get (0.0067)\n",
      "time (0.0061)\n",
      "\n",
      "Topic #3:\n",
      "game (0.0320)\n",
      "team (0.0251)\n",
      "play (0.0193)\n",
      "player (0.0156)\n",
      "win (0.0134)\n",
      "season (0.0119)\n",
      "leagu (0.0106)\n",
      "hockey (0.0095)\n",
      "score (0.0091)\n",
      "turkey (0.0085)\n",
      "\n",
      "Topic #4:\n",
      "govern (0.0099)\n",
      "state (0.0073)\n",
      "presid (0.0063)\n",
      "secur (0.0056)\n",
      "new (0.0055)\n",
      "mr (0.0053)\n",
      "law (0.0051)\n",
      "u (0.0050)\n",
      "public (0.0050)\n",
      "nation (0.0047)\n",
      "\n",
      "Topic #5:\n",
      "use (0.0218)\n",
      "key (0.0196)\n",
      "encrypt (0.0117)\n",
      "chip (0.0098)\n",
      "system (0.0091)\n",
      "one (0.0085)\n",
      "bit (0.0082)\n",
      "would (0.0066)\n",
      "get (0.0065)\n",
      "window (0.0063)\n",
      "\n",
      "Topic #6:\n",
      "god (0.0488)\n",
      "christian (0.0274)\n",
      "jesu (0.0201)\n",
      "jew (0.0174)\n",
      "church (0.0137)\n",
      "bibl (0.0123)\n",
      "believ (0.0117)\n",
      "faith (0.0113)\n",
      "religion (0.0106)\n",
      "christ (0.0098)\n",
      "\n",
      "Topic #7:\n",
      "x (0.0486)\n",
      "edu (0.0160)\n",
      "file (0.0159)\n",
      "anonym (0.0097)\n",
      "com (0.0089)\n",
      "c (0.0089)\n",
      "use (0.0086)\n",
      "mail (0.0085)\n",
      "program (0.0081)\n",
      "ftp (0.0068)\n",
      "\n",
      "Topic #8:\n",
      "car (0.0173)\n",
      "wire (0.0102)\n",
      "ground (0.0088)\n",
      "new (0.0062)\n",
      "ride (0.0055)\n",
      "hide (0.0050)\n",
      "water (0.0050)\n",
      "shot (0.0048)\n",
      "engin (0.0044)\n",
      "min (0.0043)\n",
      "\n",
      "Topic #9:\n",
      "w (0.0522)\n",
      "b (0.0501)\n",
      "q (0.0465)\n",
      "p (0.0379)\n",
      "u (0.0369)\n",
      "r (0.0343)\n",
      "c (0.0333)\n",
      "g (0.0330)\n",
      "v (0.0293)\n",
      "n (0.0284)\n",
      "\n",
      "Topic #10:\n",
      "ax (0.6211)\n",
      "max (0.0468)\n",
      "f (0.0361)\n",
      "q (0.0277)\n",
      "g (0.0208)\n",
      "v (0.0181)\n",
      "p (0.0099)\n",
      "r (0.0083)\n",
      "u (0.0082)\n",
      "b (0.0063)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Interpret the result\n",
    "# Print the topics with the top 10 words for each topic along with their weights\n",
    "topics = lda_model.show_topics(num_topics=10, num_words=10, formatted=False)\n",
    "for topic_num, terms in topics:\n",
    "    print(f'Topic #{topic_num + 1}:')\n",
    "    for term, weight in terms:\n",
    "        print(f'{term} ({weight:.4f})')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
