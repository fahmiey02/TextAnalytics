{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317cc637",
   "metadata": {},
   "source": [
    "# LAB ASSIGNMENT 2 - Sentiment Analysis of Amazon Review\n",
    "\n",
    "Group Members:-\n",
    "\n",
    "Muhammad Fahmi Bin Misri (SW01081019)\n",
    "Nik Muhammad Nafis Bin Nik Azlan (SW01081028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4152cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d14e075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9475f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf00eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data - first 1000 rows\n",
    "df = pd.read_csv(\"Reviews.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7594862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "7                     0                       0      5  1336003200   \n",
       "8                     1                       1      5  1322006400   \n",
       "9                     0                       0      5  1351209600   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                          Good Quality Dog Food   \n",
       "1                              Not as Advertised   \n",
       "2                          \"Delight\" says it all   \n",
       "3                                 Cough Medicine   \n",
       "4                                    Great taffy   \n",
       "5                                     Nice Taffy   \n",
       "6  Great!  Just as good as the expensive brands!   \n",
       "7                         Wonderful, tasty taffy   \n",
       "8                                     Yay Barley   \n",
       "9                               Healthy Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  \n",
       "5  I got a wild hair for taffy and ordered this f...  \n",
       "6  This saltwater taffy had great flavors and was...  \n",
       "7  This taffy is so good.  It is very soft and ch...  \n",
       "8  Right now I'm mostly just sprouting this so my...  \n",
       "9  This is a very healthy dog food. Good for thei...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea8c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5302604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned d...\n",
       "1    Product arrived labeled as Jumbo Salted Peanut...\n",
       "2    This is a confection that has been around a fe...\n",
       "3    If you are looking for the secret ingredient i...\n",
       "4    Great taffy at a great price.  There was a wid...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select Text column\n",
    "df_t = df['Text']\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf53e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# check no. of duplicates in Text column\n",
    "df_t_duplicates = df_t.duplicated()\n",
    "print(df_t_duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecedf106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates in Text column\n",
    "df_rdup = df_t.drop_duplicates(keep='first')\n",
    "df_rdup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80087ea",
   "metadata": {},
   "source": [
    "Removing HTML tags and unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041e01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_textdata(sentence):\n",
    "    modified_sentence = re.sub(r'<.*?>',' ', sentence)\n",
    "    modified_sentence = ''.join([i if i not in string.punctuation else ' ' for i in modified_sentence])\n",
    "    modified_sentence = re.sub(r'\\d+', ' ', modified_sentence)\n",
    "    modified_sentence = re.sub(r'\\s+', ' ', modified_sentence)\n",
    "    modified_sentence = modified_sentence.lower()\n",
    "    return modified_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f830ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdupclean = df_rdup.apply(get_cleaned_textdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "705c2d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the item over all was fine but the banana heads are not just like banana runts they are alot smaller also when i received the item the packaging was not great the banana heads had come open during shipping and were all over the packing envelope \n"
     ]
    }
   ],
   "source": [
    "# check any row\n",
    "print(df_rdupclean[169])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5b9619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i have bought several of the vitality canned d...\n",
      "1      product arrived labeled as jumbo salted peanut...\n",
      "2      this is a confection that has been around a fe...\n",
      "3      if you are looking for the secret ingredient i...\n",
      "4      great taffy at a great price there was a wide ...\n",
      "                             ...                        \n",
      "995    black market hot sauce is wonderful my husband...\n",
      "996    man what can i say this salsa is the bomb i ha...\n",
      "997    this sauce is so good with just about anything...\n",
      "998    not hot at all like the other low star reviewe...\n",
      "999    i have to admit i was a sucker for the large q...\n",
      "Name: Text, Length: 997, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_rdupclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3978245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for sentiment analysis\n",
    "df = df[['Score', 'Text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60763b",
   "metadata": {},
   "source": [
    "Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2b6779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the text into individual words\n",
    "df['Tokens'] = df['Text'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89314c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the WordNet lemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize the tokens\n",
    "df['Tokens'] = df['Tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "039f8c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>[I, have, bought, several, of, the, Vitality, ...</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>[Product, arrived, labeled, a, Jumbo, Salted, ...</td>\n",
       "      <td>Product arrived labeled a Jumbo Salted Peanuts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>[This, is, a, confection, that, ha, been, arou...</td>\n",
       "      <td>This is a confection that ha been around a few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>[If, you, are, looking, for, the, secret, ingr...</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>[Great, taffy, at, a, great, price, ., There, ...</td>\n",
       "      <td>Great taffy at a great price . There wa a wide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text  \\\n",
       "0      5  I have bought several of the Vitality canned d...   \n",
       "1      1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2      4  This is a confection that has been around a fe...   \n",
       "3      2  If you are looking for the secret ingredient i...   \n",
       "4      5  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [I, have, bought, several, of, the, Vitality, ...   \n",
       "1  [Product, arrived, labeled, a, Jumbo, Salted, ...   \n",
       "2  [This, is, a, confection, that, ha, been, arou...   \n",
       "3  [If, you, are, looking, for, the, secret, ingr...   \n",
       "4  [Great, taffy, at, a, great, price, ., There, ...   \n",
       "\n",
       "                                   Preprocessed_Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled a Jumbo Salted Peanuts...  \n",
       "2  This is a confection that ha been around a few...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price . There wa a wide...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the tokens back into sentences\n",
    "df['Preprocessed_Text'] = df['Tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Save the preprocessed data to a new CSV file\n",
    "df.to_csv('preprocessed_amazon_reviews.csv', index=False)\n",
    "\n",
    "# Preview the preprocessed data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2aa789",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION (BAG OF WORDS AND TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b875a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0d801",
   "metadata": {},
   "source": [
    "Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f401032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW feature shape: (1000, 5549)\n",
      "Vocabulary size: 5549\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "bow_features = vectorizer.fit_transform(df['Preprocessed_Text'])\n",
    "\n",
    "# Get the vocabulary (unique words)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the shape of the BoW features and the vocabulary size\n",
    "print(\"BoW feature shape:\", bow_features.shape)\n",
    "print(\"Vocabulary size:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42acd50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: List of Unique Words: ['a', 'this', 'the', 'were', 'intended', 'product', 'robitussin', 'quick', 'are', 'so', 'unsalted', 'soda', 'assortment', 'amazing', 'you', 'salted', 'ingredient', 'deal', 'as', 'flavors', 'if', 'medicinal', 'flavor', 'actually', 'sure', 'error', 'good', 'which', 'in', 'believe', 'is', 'there', 'satisfying', 'addition', 'vendor', 'great', 'i', 'wide', 'found', 'made', 'for', 'extract', 'represent', 'labeled', 'chewy', 'have', 'secret', 'looking', 'or', 'peanuts', 'it', 'sized', 'lover', 'delivery', 'jumboif', 'price', 'your', 'arrived', 'very', 'small', 'to', 'was', 'of', 'root', 'and', 'jumbo', 'recommend', 'cherry', 'not', 'yummy', 'at', 'would', 'definitely', 'buying', 'taffy', 'some', 'soft', 'an', 'got', 'ordered', 'beer']\n",
      "\n",
      "Step 2: Word Frequency Table:\n",
      "Word\tFrequency\n",
      "the\t7\n",
      "i\t5\n",
      "this\t4\n",
      "was\t4\n",
      "is\t4\n",
      "very\t4\n",
      "taffy\t4\n",
      "a\t4\n",
      "if\t3\n",
      "it\t3\n",
      "product\t2\n",
      "as\t2\n",
      "peanuts\t2\n",
      "to\t2\n",
      "you\t2\n",
      "are\t2\n",
      "in\t2\n",
      "good\t2\n",
      "and\t2\n",
      "great\t2\n",
      "arrived\t1\n",
      "labeled\t1\n",
      "jumbo\t1\n",
      "salted\t1\n",
      "were\t1\n",
      "actually\t1\n",
      "small\t1\n",
      "sized\t1\n",
      "unsalted\t1\n",
      "not\t1\n",
      "sure\t1\n",
      "an\t1\n",
      "error\t1\n",
      "or\t1\n",
      "vendor\t1\n",
      "intended\t1\n",
      "represent\t1\n",
      "jumboif\t1\n",
      "looking\t1\n",
      "for\t1\n",
      "secret\t1\n",
      "ingredient\t1\n",
      "robitussin\t1\n",
      "believe\t1\n",
      "have\t1\n",
      "found\t1\n",
      "got\t1\n",
      "addition\t1\n",
      "root\t1\n",
      "beer\t1\n",
      "extract\t1\n",
      "ordered\t1\n",
      "which\t1\n",
      "made\t1\n",
      "some\t1\n",
      "cherry\t1\n",
      "soda\t1\n",
      "flavor\t1\n",
      "medicinal\t1\n",
      "at\t1\n",
      "price\t1\n",
      "there\t1\n",
      "wide\t1\n",
      "assortment\t1\n",
      "of\t1\n",
      "yummy\t1\n",
      "delivery\t1\n",
      "quick\t1\n",
      "your\t1\n",
      "lover\t1\n",
      "deal\t1\n",
      "so\t1\n",
      "soft\t1\n",
      "chewy\t1\n",
      "flavors\t1\n",
      "amazing\t1\n",
      "would\t1\n",
      "definitely\t1\n",
      "recommend\t1\n",
      "buying\t1\n",
      "satisfying\t1\n",
      "\n",
      "Step 3: Document Vectors:\n",
      "Sentence: product arrived labeled as jumbo salted peanuts the peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumboif you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal\n",
      "Vector: [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Sentence: great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal\n",
      "Vector: [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Sentence: this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying\n",
      "Vector: [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Given list of sentences\n",
    "sentences = [\n",
    "    \"product arrived labeled as jumbo salted peanuts the peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo\"\n",
    "    \"if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal\",\n",
    "    \"great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal\",\n",
    "    \"this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying\"\n",
    "]\n",
    "\n",
    "# Step 1: List all unique words\n",
    "all_words = ' '.join(sentences).split()\n",
    "unique_words = list(set(all_words))\n",
    "\n",
    "# Step 2: Create word frequency table\n",
    "word_freq = Counter(all_words)\n",
    "sorted_word_freq = dict(sorted(word_freq.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Step 3: Create document vectors\n",
    "document_vectors = []\n",
    "for sentence in sentences:\n",
    "    sentence_words = sentence.split()\n",
    "    document_vector = [1 if word in sentence_words else 0 for word in sorted_word_freq.keys()]\n",
    "    document_vectors.append(document_vector)\n",
    "\n",
    "# Print the results\n",
    "print(\"Step 1: List of Unique Words:\", unique_words)\n",
    "print(\"\\nStep 2: Word Frequency Table:\")\n",
    "print(\"Word\\tFrequency\")\n",
    "for word, freq in sorted_word_freq.items():\n",
    "    print(f\"{word}\\t{freq}\")\n",
    "\n",
    "print(\"\\nStep 3: Document Vectors:\")\n",
    "for sentence, vector in zip(sentences, document_vectors):\n",
    "    print(f\"Sentence: {sentence}\\nVector: {vector}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7bcdb8",
   "metadata": {},
   "source": [
    "Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e8143d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (1000, 5549)\n",
      "Vocabulary size: 5549\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['Preprocessed_Text'])\n",
    "\n",
    "# Get the vocabulary (unique words)\n",
    "tfidf_vocabulary = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the shape of the TF-IDF features and the vocabulary size\n",
    "print(\"TF-IDF feature shape:\", tfidf_features.shape)\n",
    "print(\"Vocabulary size:\", len(tfidf_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8281000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Scores:\n",
      "      great     taffy        at         a     price     there       was  \\\n",
      "0  0.074074  0.111111  0.037037  0.148148  0.037037  0.037037  0.074074   \n",
      "1  0.000000  0.041667  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       wide  assortment        of  ...   flavors       are   amazing  \\\n",
      "0  0.037037    0.037037  0.037037  ...  0.000000  0.000000  0.000000   \n",
      "1  0.000000    0.000000  0.000000  ...  0.041667  0.041667  0.041667   \n",
      "\n",
      "          i     would  definitely  recommend       you    buying  satisfying  \n",
      "0  0.000000  0.000000    0.000000   0.000000  0.000000  0.000000    0.000000  \n",
      "1  0.041667  0.041667    0.041667   0.041667  0.041667  0.041667    0.041667  \n",
      "\n",
      "[2 rows x 37 columns]\n",
      "\n",
      "IDF Scores:\n",
      "       wide     price         a      your  this   flavors       the  very  \\\n",
      "0  0.693147  0.693147  0.693147  0.693147   0.0  0.693147  0.693147   0.0   \n",
      "\n",
      "         if       was  ...   is     there      soft  satisfying      deal  \\\n",
      "0  0.693147  0.693147  ...  0.0  0.693147  0.693147    0.693147  0.693147   \n",
      "\n",
      "         it     great     lover  delivery         i  \n",
      "0  0.693147  0.693147  0.693147  0.693147  0.693147  \n",
      "\n",
      "[1 rows x 37 columns]\n",
      "\n",
      "TF-IDF Scores:\n",
      "      great  taffy        at         a     price     there       was  \\\n",
      "0  0.051344    0.0  0.025672  0.102688  0.025672  0.025672  0.051344   \n",
      "1  0.000000    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       wide  assortment        of  ...   flavors       are   amazing  \\\n",
      "0  0.025672    0.025672  0.025672  ...  0.000000  0.000000  0.000000   \n",
      "1  0.000000    0.000000  0.000000  ...  0.028881  0.028881  0.028881   \n",
      "\n",
      "          i     would  definitely  recommend       you    buying  satisfying  \n",
      "0  0.000000  0.000000    0.000000   0.000000  0.000000  0.000000    0.000000  \n",
      "1  0.028881  0.028881    0.028881   0.028881  0.028881  0.028881    0.028881  \n",
      "\n",
      "[2 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def compute_tf(document):\n",
    "    word_count = Counter(document)\n",
    "    tf = {word: count/len(document) for word, count in word_count.items()}\n",
    "    return tf\n",
    "\n",
    "def compute_idf(documents):\n",
    "    N = len(documents)\n",
    "    idf = {}\n",
    "    all_words = set(word for doc in documents for word in doc)\n",
    "    for word in all_words:\n",
    "        count = sum(1 for doc in documents if word in doc)\n",
    "        idf[word] = math.log(N/count)\n",
    "    return idf\n",
    "\n",
    "def compute_tfidf(document, idf):\n",
    "    tfidf = {}\n",
    "    tf = compute_tf(document)\n",
    "    for word, tf_value in tf.items():\n",
    "        tfidf[word] = tf_value * idf[word]\n",
    "    return tfidf\n",
    "\n",
    "# New data\n",
    "data = [\n",
    "    \"great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal\",\n",
    "    \"this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying\"\n",
    "]\n",
    "\n",
    "# Split data into tokens\n",
    "documents = [doc.split() for doc in data]\n",
    "\n",
    "# Compute TF for each document\n",
    "tf_data = [compute_tf(doc) for doc in documents]\n",
    "\n",
    "# Create DataFrame for TF\n",
    "tf_df = pd.DataFrame(tf_data).fillna(0)\n",
    "print(\"TF Scores:\")\n",
    "print(tf_df)\n",
    "\n",
    "# Compute IDF\n",
    "idf = compute_idf(documents)\n",
    "idf_df = pd.DataFrame([idf]).fillna(0)\n",
    "print(\"\\nIDF Scores:\")\n",
    "print(idf_df)\n",
    "\n",
    "# Compute TF-IDF for each document\n",
    "tfidf_data = [compute_tfidf(doc, idf) for doc in documents]\n",
    "\n",
    "# Create DataFrame for TF-IDF\n",
    "tfidf_df = pd.DataFrame(tfidf_data).fillna(0)\n",
    "print(\"\\nTF-IDF Scores:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeaeafe",
   "metadata": {},
   "source": [
    "# Model Selection (LEXICON APPROACH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4e656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tabulate import tabulate\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621317e0",
   "metadata": {},
   "source": [
    "1. Lexicon-based approach using NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df8e0420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Fahmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon-based Approach Accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Assign sentiment labels based on the 'Score' column\n",
    "def assign_sentiment(score):\n",
    "    if score >= 4:\n",
    "        return 'Positive'\n",
    "    elif score <= 2:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment'] = df['Score'].apply(assign_sentiment)\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores for each review\n",
    "df['Lexicon_Sentiment'] = df['Preprocessed_Text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "\n",
    "# Map sentiment scores to labels\n",
    "df['Lexicon_Sentiment_Label'] = df['Lexicon_Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "# Evaluate the lexicon-based approach\n",
    "lexicon_accuracy = accuracy_score(df['Sentiment'], df['Lexicon_Sentiment_Label'])\n",
    "print(\"Lexicon-based Approach Accuracy:\", lexicon_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acda8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"good flavor these came securely packed they were fresh and delicious i love these twizzlers\", 'positive'),\n",
    "    (\"this is the same stuff you can buy at the big box stores there is nothing healthy about it it is just carbs and sugars save your money and get something that at least has some taste\", 'negative'),\n",
    "    (\"the flavors are good however i do not see any differce between this and oaker oats brand they are both mushy\", 'neutral'),\n",
    "    (\"the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i\", 'positive'),\n",
    "    (\"this oatmeal is not good its mushy soft i don t like it quaker oats is the way to go\", 'negative'),\n",
    "    (\"halloween is over but i sent a bag to my daughters class for her share the chocolate was fresh and enjoyed by many\", 'neutral'),\n",
    "    (\"my daughter loves twizzlers and this shipment of six pounds really hit the spot it s exactly what you would expect six packages of strawberry twizzlers\", 'positive'),\n",
    "    (\"arrived in days and were so stale i could not eat any of the bags\", 'negative'),\n",
    "    (\"this bag of candy online is pretty expensive it should be cheaper in order to compete with grocery stores other than that its a good combination of my favorite candy\", 'neutral'),\n",
    "    (\"i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them\", 'positive'),\n",
    "    (\"no tea flavor at all just whole brunch of artifial flavors it is not returnable i wasted bucks\", 'negative'),\n",
    "    (\"this stuff really works for preventing cramping during the middle to latter stages of your rides pop into each water bottle and you re set flavor is fine and goes down easy\", 'neutral'),\n",
    "    (\"i fed this to my golden retriever and he hated it he wouldn t eat it and when he did it gave him terrible diarrhea we will not be buying this again it s also super expensive\", 'negative'),\n",
    "    (\"i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more\", 'positive'),\n",
    "    (\"it is okay i would not go out of my way to buy it again\", 'neutral'),\n",
    "    (\"candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me\", 'positive'),\n",
    "    (\"not what i was expecting in terms of the company s reputation for excellent home delivery products\", 'negative'),\n",
    "    (\"this is the same food we get at pet store but it s delivered to my door and for the same price or slightly less \", 'neutral'),\n",
    "    (\"i can remember buying this candy as a kid and the quality hasn t dropped in all these years still a superb product you won t be disappointed with\", 'positive'),\n",
    "    (\"i was disappointed in the flavor and texture of this mix i usually like most of the low carb things i have tried but was diappointed in this specific one \", 'negative'),\n",
    "    (\"i ve been eating ramen noodles since i was a little kid and i ve never found a better flavor than hot spicy chicken it isn t hot at all to a chilihead like me but it sure is good\", 'neutral'),\n",
    "    (\"this was sooooo deliscious but too bad i ate em too fast and gained pds my fault\", 'positive'),\n",
    "    (\"besides being smaller than runts they look the same and have the same consistency unfortunately they taste nothing like banana runts nor do they even taste good yucky stuff trying to return with vendor\", 'negative'),\n",
    "    (\"the item over all was fine but the banana heads are not just like banana runts they are alot smaller also when i received the item the packaging was not great the banana heads had come open during shipping and were all over the packing envelope\", 'neutral'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0af079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = [[\"Text\", \"Actual Label\", \"TextBlob Polarity\", \"TextBlob Sentiment\", \"VADER Compound\", \"VADER Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23bc03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, actual_label in data:\n",
    "    # TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    tb_polarity = blob.sentiment.polarity\n",
    "    \n",
    "    # Determine label based on polarity score from TextBlob\n",
    "    if tb_polarity > 0:\n",
    "        tb_label = 'positive'\n",
    "    elif tb_polarity < 0:\n",
    "        tb_label = 'negative'\n",
    "    else:\n",
    "        tb_label = 'neutral'\n",
    "\n",
    "    # VADER\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    vader_compound = vs['compound']\n",
    "\n",
    "    # Determine label based on compound score from VADER\n",
    "    if vader_compound > 0.05:\n",
    "        vader_label = 'positive'\n",
    "    elif vader_compound < -0.05:\n",
    "        vader_label = 'negative'\n",
    "    else:\n",
    "        vader_label = 'neutral'\n",
    "\n",
    "    table_data.append([text, actual_label, tb_polarity, tb_label, vader_compound, vader_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73169c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                                                                                                                                                                                                                                  Actual Label      TextBlob Polarity  TextBlob Sentiment      VADER Compound  VADER Sentiment\n",
      "good flavor these came securely packed they were fresh and delicious i love these twizzlers                                                                                                                                                           positive                 0.58        positive                        0.9382  positive\n",
      "this is the same stuff you can buy at the big box stores there is nothing healthy about it it is just carbs and sugars save your money and get something that at least has some taste                                                                 negative                 0.05        positive                        0.2363  positive\n",
      "the flavors are good however i do not see any differce between this and oaker oats brand they are both mushy                                                                                                                                          neutral                  0.7         positive                        0.4404  positive\n",
      "the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i                                                                                                                                         positive                -0.5         negative                        0.6486  positive\n",
      "this oatmeal is not good its mushy soft i don t like it quaker oats is the way to go                                                                                                                                                                  negative                -0.125       negative                        0.0243  neutral\n",
      "halloween is over but i sent a bag to my daughters class for her share the chocolate was fresh and enjoyed by many                                                                                                                                    neutral                  0.433333    positive                        0.8807  positive\n",
      "my daughter loves twizzlers and this shipment of six pounds really hit the spot it s exactly what you would expect six packages of strawberry twizzlers                                                                                               positive                 0.225       positive                        0.5719  positive\n",
      "arrived in days and were so stale i could not eat any of the bags                                                                                                                                                                                     negative                -0.5         negative                        0       neutral\n",
      "this bag of candy online is pretty expensive it should be cheaper in order to compete with grocery stores other than that its a good combination of my favorite candy                                                                                 neutral                  0.165       positive                        0.8442  positive\n",
      "i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them                                                      positive                 0.4625      positive                        0.7247  positive\n",
      "no tea flavor at all just whole brunch of artifial flavors it is not returnable i wasted bucks                                                                                                                                                        negative                 0           neutral                         0.1098  positive\n",
      "this stuff really works for preventing cramping during the middle to latter stages of your rides pop into each water bottle and you re set flavor is fine and goes down easy                                                                          neutral                  0.149074    positive                        0.5165  positive\n",
      "i fed this to my golden retriever and he hated it he wouldn t eat it and when he did it gave him terrible diarrhea we will not be buying this again it s also super expensive                                                                         negative                -0.353333    negative                       -0.5267  negative\n",
      "i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more                                                                                                              positive                 0.4125      positive                        0.8883  positive\n",
      "it is okay i would not go out of my way to buy it again                                                                                                                                                                                               neutral                  0.5         positive                        0.2263  positive\n",
      "candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me                                                                                                        positive                 0.24        positive                        0.6077  positive\n",
      "not what i was expecting in terms of the company s reputation for excellent home delivery products                                                                                                                                                    negative                 1           positive                        0.5719  positive\n",
      "this is the same food we get at pet store but it s delivered to my door and for the same price or slightly less                                                                                                                                       neutral                 -0.0555556   negative                        0       neutral\n",
      "i can remember buying this candy as a kid and the quality hasn t dropped in all these years still a superb product you won t be disappointed with                                                                                                     positive                 0.125       positive                        0.6908  positive\n",
      "i was disappointed in the flavor and texture of this mix i usually like most of the low carb things i have tried but was diappointed in this specific one                                                                                             negative                -0.1         negative                       -0.2457  negative\n",
      "i ve been eating ramen noodles since i was a little kid and i ve never found a better flavor than hot spicy chicken it isn t hot at all to a chilihead like me but it sure is good                                                                    neutral                  0.201786    positive                        0.7812  positive\n",
      "this was sooooo deliscious but too bad i ate em too fast and gained pds my fault                                                                                                                                                                      positive                -0.25        negative                       -0.7096  negative\n",
      "besides being smaller than runts they look the same and have the same consistency unfortunately they taste nothing like banana runts nor do they even taste good yucky stuff trying to return with vendor                                             negative                 0.04        positive                       -0.5283  negative\n",
      "the item over all was fine but the banana heads are not just like banana runts they are alot smaller also when i received the item the packaging was not great the banana heads had come open during shipping and were all over the packing envelope  neutral                  0.00416667  positive                       -0.7721  negative\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db3c8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                                                                                                                                                                                                                                  Actual Label      TextBlob Polarity  TextBlob Sentiment      VADER Compound  VADER Sentiment\n",
      "good flavor these came securely packed they were fresh and delicious i love these twizzlers                                                                                                                                                           positive                 0.58        positive                        0.9382  positive\n",
      "this is the same stuff you can buy at the big box stores there is nothing healthy about it it is just carbs and sugars save your money and get something that at least has some taste                                                                 negative                 0.05        positive                        0.2363  positive\n",
      "the flavors are good however i do not see any differce between this and oaker oats brand they are both mushy                                                                                                                                          neutral                  0.7         positive                        0.4404  positive\n",
      "the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i                                                                                                                                         positive                -0.5         negative                        0.6486  positive\n",
      "this oatmeal is not good its mushy soft i don t like it quaker oats is the way to go                                                                                                                                                                  negative                -0.125       negative                        0.0243  neutral\n",
      "halloween is over but i sent a bag to my daughters class for her share the chocolate was fresh and enjoyed by many                                                                                                                                    neutral                  0.433333    positive                        0.8807  positive\n",
      "my daughter loves twizzlers and this shipment of six pounds really hit the spot it s exactly what you would expect six packages of strawberry twizzlers                                                                                               positive                 0.225       positive                        0.5719  positive\n",
      "arrived in days and were so stale i could not eat any of the bags                                                                                                                                                                                     negative                -0.5         negative                        0       neutral\n",
      "this bag of candy online is pretty expensive it should be cheaper in order to compete with grocery stores other than that its a good combination of my favorite candy                                                                                 neutral                  0.165       positive                        0.8442  positive\n",
      "i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them                                                      positive                 0.4625      positive                        0.8652  positive\n",
      "no tea flavor at all just whole brunch of artifial flavors it is not returnable i wasted bucks                                                                                                                                                        negative                 0           neutral                         0.1098  positive\n",
      "this stuff really works for preventing cramping during the middle to latter stages of your rides pop into each water bottle and you re set flavor is fine and goes down easy                                                                          neutral                  0.149074    positive                        0.5165  positive\n",
      "i fed this to my golden retriever and he hated it he wouldn t eat it and when he did it gave him terrible diarrhea we will not be buying this again it s also super expensive                                                                         negative                -0.353333    negative                       -0.5267  negative\n",
      "i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more                                                                                                              positive                 0.4125      positive                        0.8883  positive\n",
      "it is okay i would not go out of my way to buy it again                                                                                                                                                                                               neutral                  0.5         positive                        0.2263  positive\n",
      "candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me                                                                                                        positive                 0.24        positive                        0.6077  positive\n",
      "not what i was expecting in terms of the company s reputation for excellent home delivery products                                                                                                                                                    negative                 1           positive                        0.5719  positive\n",
      "this is the same food we get at pet store but it s delivered to my door and for the same price or slightly less                                                                                                                                       neutral                 -0.0555556   negative                        0       neutral\n",
      "i can remember buying this candy as a kid and the quality hasn t dropped in all these years still a superb product you won t be disappointed with                                                                                                     positive                 0.125       positive                        0.6908  positive\n",
      "i was disappointed in the flavor and texture of this mix i usually like most of the low carb things i have tried but was diappointed in this specific one                                                                                             negative                -0.1         negative                       -0.2457  negative\n",
      "i ve been eating ramen noodles since i was a little kid and i ve never found a better flavor than hot spicy chicken it isn t hot at all to a chilihead like me but it sure is good                                                                    neutral                  0.201786    positive                        0.7812  positive\n",
      "this was sooooo deliscious but too bad i ate em too fast and gained pds my fault                                                                                                                                                                      positive                -0.25        negative                       -0.7096  negative\n",
      "besides being smaller than runts they look the same and have the same consistency unfortunately they taste nothing like banana runts nor do they even taste good yucky stuff trying to return with vendor                                             negative                 0.04        positive                       -0.5283  negative\n",
      "the item over all was fine but the banana heads are not just like banana runts they are alot smaller also when i received the item the packaging was not great the banana heads had come open during shipping and were all over the packing envelope  neutral                  0.00416667  positive                       -0.7721  negative\n",
      "\n",
      "Classification Report for TextBlob:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.50      0.53         8\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.38      0.75      0.50         8\n",
      "\n",
      "    accuracy                           0.42        24\n",
      "   macro avg       0.32      0.42      0.34        24\n",
      "weighted avg       0.32      0.42      0.34        24\n",
      "\n",
      "\n",
      "Classification Report for VADER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.38      0.46         8\n",
      "     neutral       0.33      0.12      0.18         8\n",
      "    positive       0.44      0.88      0.58         8\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.46      0.46      0.41        24\n",
      "weighted avg       0.46      0.46      0.41        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    (\"good flavor these came securely packed they were fresh and delicious i love these twizzlers\", 'positive'),\n",
    "    (\"this is the same stuff you can buy at the big box stores there is nothing healthy about it it is just carbs and sugars save your money and get something that at least has some taste\", 'negative'),\n",
    "    (\"the flavors are good however i do not see any differce between this and oaker oats brand they are both mushy\", 'neutral'),\n",
    "    (\"the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i\", 'positive'),\n",
    "    (\"this oatmeal is not good its mushy soft i don t like it quaker oats is the way to go\", 'negative'),\n",
    "    (\"halloween is over but i sent a bag to my daughters class for her share the chocolate was fresh and enjoyed by many\", 'neutral'),\n",
    "    (\"my daughter loves twizzlers and this shipment of six pounds really hit the spot it s exactly what you would expect six packages of strawberry twizzlers\", 'positive'),\n",
    "    (\"arrived in days and were so stale i could not eat any of the bags\", 'negative'),\n",
    "    (\"this bag of candy online is pretty expensive it should be cheaper in order to compete with grocery stores other than that its a good combination of my favorite candy\", 'neutral'),\n",
    "    (\"i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them\", 'positive'),\n",
    "    (\"no tea flavor at all just whole brunch of artifial flavors it is not returnable i wasted bucks\", 'negative'),\n",
    "    (\"this stuff really works for preventing cramping during the middle to latter stages of your rides pop into each water bottle and you re set flavor is fine and goes down easy\", 'neutral'),\n",
    "    (\"i fed this to my golden retriever and he hated it he wouldn t eat it and when he did it gave him terrible diarrhea we will not be buying this again it s also super expensive\", 'negative'),\n",
    "    (\"i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more\", 'positive'),\n",
    "    (\"it is okay i would not go out of my way to buy it again\", 'neutral'),\n",
    "    (\"candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me\", 'positive'),\n",
    "    (\"not what i was expecting in terms of the company s reputation for excellent home delivery products\", 'negative'),\n",
    "    (\"this is the same food we get at pet store but it s delivered to my door and for the same price or slightly less \", 'neutral'),\n",
    "    (\"i can remember buying this candy as a kid and the quality hasn t dropped in all these years still a superb product you won t be disappointed with\", 'positive'),\n",
    "    (\"i was disappointed in the flavor and texture of this mix i usually like most of the low carb things i have tried but was diappointed in this specific one \", 'negative'),\n",
    "    (\"i ve been eating ramen noodles since i was a little kid and i ve never found a better flavor than hot spicy chicken it isn t hot at all to a chilihead like me but it sure is good\", 'neutral'),\n",
    "    (\"this was sooooo deliscious but too bad i ate em too fast and gained pds my fault\", 'positive'),\n",
    "    (\"besides being smaller than runts they look the same and have the same consistency unfortunately they taste nothing like banana runts nor do they even taste good yucky stuff trying to return with vendor\", 'negative'),\n",
    "    (\"the item over all was fine but the banana heads are not just like banana runts they are alot smaller also when i received the item the packaging was not great the banana heads had come open during shipping and were all over the packing envelope\", 'neutral'),\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the data in tabular format\n",
    "table_data = [[\"Text\", \"Actual Label\", \"TextBlob Polarity\", \"TextBlob Sentiment\", \"VADER Compound\", \"VADER Sentiment\"]]\n",
    "\n",
    "# Lexicon-based approach using TextBlob and VADER\n",
    "for text, actual_label in data:\n",
    "    # TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    tb_polarity = blob.sentiment.polarity\n",
    "    \n",
    "    # Determine label based on polarity score from TextBlob\n",
    "    if tb_polarity > 0:\n",
    "        tb_label = 'positive'\n",
    "    elif tb_polarity < 0:\n",
    "        tb_label = 'negative'\n",
    "    else:\n",
    "        tb_label = 'neutral'\n",
    "\n",
    "    # VADER\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    vader_compound = vs['compound']\n",
    "   \n",
    "    # Determine label based on compound score from VADER\n",
    "    if vader_compound > 0.05:\n",
    "        vader_label = 'positive'\n",
    "    elif vader_compound < -0.05:\n",
    "        vader_label = 'negative'\n",
    "    else:\n",
    "        vader_label = 'neutral'\n",
    "\n",
    "    table_data.append([text, actual_label, tb_polarity, tb_label, vader_compound, vader_label])\n",
    "\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"plain\"))\n",
    "\n",
    "# Calculate classification report for TextBlob\n",
    "tb_actual_labels = [label for _, label, _, _, _, _ in table_data[1:]]\n",
    "tb_predicted_labels = [tb_label for _, _, _, tb_label, _, _ in table_data[1:]]\n",
    "tb_classification_report = classification_report(tb_actual_labels, tb_predicted_labels, target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Calculate classification report for VADER\n",
    "vader_actual_labels = [label for _, label, _, _, _, _ in table_data[1:]]\n",
    "vader_predicted_labels = [vader_label for _, _, _, _, _, vader_label in table_data[1:]]\n",
    "vader_classification_report = classification_report(vader_actual_labels, vader_predicted_labels, target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Print classification report for TextBlob\n",
    "print(\"\\nClassification Report for TextBlob:\")\n",
    "print(tb_classification_report)\n",
    "\n",
    "# Print classification report for VADER\n",
    "print(\"\\nClassification Report for VADER:\")\n",
    "print(vader_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd310a",
   "metadata": {},
   "source": [
    "# MODEL SELECTION (Machine Learning Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49aa8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285b82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        25\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.82      1.00      0.90       164\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.27      0.33      0.30       200\n",
      "weighted avg       0.67      0.82      0.74       200\n",
      "\n",
      "SVM Accuracy: 0.845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.32      0.44        25\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.85      0.98      0.91       164\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.53      0.43      0.45       200\n",
      "weighted avg       0.79      0.84      0.80       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Fahmi\\anaconda3\\envs\\DATAVISUAL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Preprocessed_Text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Train and evaluate Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(classification_report(y_test, nb_predictions))\n",
    "\n",
    "# Train and evaluate SVM classifier\n",
    "svm_classifier = LinearSVC()\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cdbdff",
   "metadata": {},
   "source": [
    "# Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da13fe8",
   "metadata": {},
   "source": [
    "Let's delve into the strengths and weaknesses of the chosen sentiment classification models, considering both the experimental outcomes and the attributes of the Amazon Fine Food Reviews dataset.\n",
    "\n",
    "\n",
    "Lexicon-based Approach Accuracy: 0.804\n",
    "Naive Bayes Accuracy: 0.82\n",
    "SVM Accuracy: 0.845\n",
    "\n",
    "1. Lexicon-based Approach (VADER):\n",
    "Strengths:\n",
    "\n",
    "- VADER offers a decent accuracy of 0.804, indicating its ability to capture sentiment to some extent.\n",
    "\n",
    "- It is relatively simple to implement and can provide quick insights into sentiment without extensive computational resources.\n",
    "\n",
    "- VADER incorporates sentiment intensity scores, which can offer nuanced sentiment analysis, distinguishing between strong and weak sentiments.\n",
    "\n",
    "Weaknesses:\n",
    "\n",
    "- While VADER performs reasonably well, its accuracy (0.804) is lower compared to machine learning models like Naive Bayes and SVM in this context.\n",
    "\n",
    "- It might struggle with context understanding and nuanced sentiment analysis, especially in cases of sarcasm or complex linguistic expressions.\n",
    "\n",
    "- VADER's performance heavily relies on the sentiment lexicon it's based on, which might not cover all domain-specific sentiments or newly emerging terms.\n",
    "\n",
    "2. Naive Bayes Classifier:\n",
    "- The Naive Bayes classifier achieves an accuracy of 0.82, indicating its effectiveness in capturing sentiment patterns in the dataset.\n",
    "\n",
    "- Naive Bayes is known for its simplicity, speed, and efficiency, making it suitable for tasks with limited computational resources.\n",
    "\n",
    "- It can handle a large number of features (words) efficiently, making it scalable to different datasets and domains.\n",
    "\n",
    "Weaknesses:\n",
    "- While Naive Bayes performs well, its accuracy (0.82) is slightly lower compared to the SVM classifier in this scenario.\n",
    "\n",
    "- Naive Bayes assumes independence between features, which may not always hold true in natural language, leading to potential inaccuracies in sentiment prediction.\n",
    "\n",
    "- It may struggle with handling negations, modifiers, and subtle linguistic nuances.\n",
    "\n",
    "3. Support Vector Machine (SVM) Classifier:\n",
    "\n",
    "Strengths:\n",
    "\n",
    "- The SVM classifier demonstrates the highest accuracy among the models at 0.845, indicating its robustness in capturing sentiment patterns.\n",
    "\n",
    "- SVMs are effective in handling high-dimensional data and can learn complex decision boundaries, making them suitable for sentiment analysis tasks.\n",
    "\n",
    "- They perform well in cases where the data is not linearly separable, which can be beneficial for sentiment analysis of nuanced text data.\n",
    "\n",
    "Weaknesses:\n",
    "- SVMs can be computationally intensive, especially with large datasets, and may require more resources for training and inference compared to simpler models like Naive Bayes.\n",
    "\n",
    "- They can be sensitive to the choice of hyperparameters, and tuning these parameters effectively can impact their performance.\n",
    "\n",
    "- SVMs may not provide as much interpretability compared to simpler models like Naive Bayes or lexicon-based approaches.\n",
    "\n",
    "In summary, the Naive Bayes classifier and SVM classifier outperform the lexicon-based approach (VADER) in terms of accuracy on the Amazon Fine Food Reviews dataset. While each model has its strengths, such as simplicity for Naive Bayes, robustness for SVM, and quick insights for VADER, they also exhibit weaknesses, such as assumptions of independence for Naive Bayes, computational intensity for SVM, and potential limitations in context understanding for VADER. The choice of model depends on the specific requirements of the sentiment analysis task, including the trade-offs between accuracy, computational resources, interpretability, and the complexity of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
